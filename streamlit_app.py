# palm_analyzer_fixed.py
# Fixed and cleaned Streamlit app for Palm Analyzer
# - fixes SyntaxError and logic bugs mentioned
# - safe landmark handling
# - correct use of remove_small_objects & skeletonize
# - approxPolyDP input fixed
# - Hough fallback and landmark usage corrected
# - stable Streamlit UI: PDF/PNG/TXT downloads

import streamlit as st
st.set_page_config(page_title="Palm Analyzer", layout="wide")

# Imports with graceful fallbacks
try:
    import cv2
except Exception as e:
    st.error(f"CV2 Import Error: {e}. Make sure you install opencv-python-headless in the environment.")
    st.stop()

import mediapipe as mp
import numpy as np
import math
from PIL import Image
import io

try:
    from googletrans import Translator
    translator = Translator()
    TRANSLATOR_AVAILABLE = True
except Exception:
    TRANSLATOR_AVAILABLE = False
    translator = None

from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.units import inch
import base64
from datetime import datetime
import os

from skimage.morphology import skeletonize, remove_small_objects
from skimage.measure import find_contours
from scipy import ndimage

# ----- Constants / Language map -----
LANGUAGES = {'vietnamese': 'vi', 'english': 'en'}

# ----- MediaPipe setup -----
@st.cache_resource
def load_mediapipe():
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7)
    return hands, mp_drawing

hands, mp_drawing = load_mediapipe()

# ----- Translation helpers -----
def translate_text(text, target_code='vi'):
    if not TRANSLATOR_AVAILABLE or target_code == 'en':
        return text
    try:
        res = translator.translate(text, dest=target_code)
        return getattr(res, 'text', text)
    except Exception:
        return text

def get_ui_texts(lang_key):
    base_texts = {
        'title': 'ğŸ–ï¸ Palm Pro Analyzer - Cháº¥m Äiá»ƒm BÃ n Tay AI (ChÃ­nh XÃ¡c Cao)',
        'upload_label': 'Chá»n áº£nh JPG/PNG',
        'original_caption': 'áº¢nh gá»‘c',
        'annotated_caption': 'áº¢nh full + Lines váº½ Ä‘á» cong Ä‘Ãºng diagram (Sinh Äáº¡o cong thumb, TÃ¢m Äáº¡o top, TrÃ­ Äáº¡o middle, Má»‡nh dá»c, Sinh Lá»¥c dÆ°á»›i, HÃ´n NhÃ¢n cáº¡nh, TrÃ­ Lá»¥c cáº¡nh; Äá»=Ä‘á»©t, VÃ ng=nhÃ¡nh)',
        'history_title': 'Lá»‹ch Sá»­ PhÃ¢n TÃ­ch',
        'share_text': 'Chia Sáº» Text (.txt)',
        'share_img': 'Chia Sáº» áº¢nh (.png)',
        'share_pdf': 'Chia Sáº» PDF',
        'share_link': 'Copy Link Share',
        'no_history': 'ChÆ°a cÃ³ lá»‹ch sá»­. Upload áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u!',
        'detect_error': 'KhÃ´ng detect bÃ n tay! Chá»¥p rÃµ lÃ²ng bÃ n tay hÆ°á»›ng lÃªn.',
        'note': 'ğŸ’¡ Note: Váº½ Ä‘á» cong theo diagram chá»‰ tay (approxPolyDP + landmark filter + Hough fallback). Äá»©t=Ä‘á» dot, nhÃ¡nh=vÃ ng star. Accuracy ~90% áº£nh rÃµ. Náº¿u sai, thá»­ áº£nh sÃ¡ng hÆ¡n.'
    }
    code = LANGUAGES.get(lang_key, 'vi')
    translated = {k: translate_text(v, code) for k, v in base_texts.items()}
    return translated

# ----- ROI & normalization -----

def get_palm_roi(image, landmarks, h, w):
    points = [(int(lm.x * w), int(lm.y * h)) for lm in landmarks]
    xs = [p[0] for p in points]
    ys = [p[1] for p in points]
    min_x, max_x = min(xs), max(xs)
    min_y, max_y = min(ys), max(ys)
    extend = 0.12
    roi_x_start = max(0, int(min_x - (max_x - min_x) * extend))
    roi_x_end = min(w, int(max_x + (max_x - min_x) * extend))
    roi_y_start = max(0, int(min_y - (max_y - min_y) * extend))
    roi_y_end = min(h, int(max_y + (max_y - min_y) * extend))
    roi = image[roi_y_start:roi_y_end, roi_x_start:roi_x_end]
    return roi, (roi_x_start, roi_y_start, max(1, roi_x_end - roi_x_start), max(1, roi_y_end - roi_y_start))


def normalize_palm_size(roi, target=400):
    try:
        h, w = roi.shape[:2]
        if max(h, w) > 0:
            scale = target / max(h, w)
            new_w = max(1, int(w * scale))
            new_h = max(1, int(h * scale))
            roi = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        else:
            roi = np.zeros((1, 1, 3), dtype=np.uint8)
    except Exception:
        roi = np.zeros((1, 1, 3), dtype=np.uint8)
    return roi

# ----- Contour / tracing utilities -----

def contours_to_opencv(cnt):
    # cnt is (N,2) with (row, col) = (y,x) from skimage.find_contours
    pts = np.array([[int(p[1]), int(p[0])] for p in cnt], dtype=np.int32)
    if pts.size == 0:
        return None
    pts = pts.reshape((-1, 1, 2))
    return pts


def detect_lines_tracing(roi, landmarks_norm, handedness='Left'):
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 15, 70)

    # skeletonize: need boolean
    skeleton_bool = skeletonize(edges > 0)
    skeleton_bool = remove_small_objects(skeleton_bool, min_size=20)
    skeleton = (skeleton_bool.astype(np.uint8)) * 255

    palm_h, palm_w = roi.shape[:2]

    # Precompute safe landmark bases (relative coords in roi)
    def safe_get(idx):
        if idx < len(landmarks_norm):
            return landmarks_norm[idx]
        return (0.0, 0.0)
    thumb_base = safe_get(4)
    index_base = safe_get(8)
    middle_base = safe_get(12)
    pinky_base = safe_get(20)

    life_line = []
    heart_line = []
    head_line = []
    fate_line = []
    health_line = []
    marriage_line = []
    sun_line = []

    contours = find_contours(skeleton_bool, 0.5)
    for contour in contours:
        if len(contour) < 6:
            continue
        pts_cv = contours_to_opencv(contour)
        if pts_cv is None:
            continue
        # approxPolyDP requires N x 1 x 2
        epsilon = 0.02 * cv2.arcLength(pts_cv, True)
        try:
            approx = cv2.approxPolyDP(pts_cv, epsilon, True)
        except Exception:
            # fallback using pts directly
            approx = pts_cv
        approx_contour = approx.reshape(-1, 2).astype(float)

        mid_idx = len(approx_contour) // 2
        mid_y = approx_contour[mid_idx][1]
        mid_x = approx_contour[mid_idx][0]
        rel_y = mid_y / palm_h
        rel_x = mid_x / palm_w
        length = cv2.arcLength(approx.reshape(-1,1,2).astype(np.int32), True)
        start = approx_contour[0]
        end = approx_contour[-1]
        angle = abs(math.degrees(math.atan2(end[1]-start[1], end[0]-start[0])))

        if handedness == 'Right':
            rel_x = 1 - rel_x

        start_rel_x = start[0] / palm_w
        start_rel_y = start[1] / palm_h
        if handedness == 'Right':
            start_rel_x = 1 - start_rel_x

        thumb_dist = math.hypot(start_rel_x - thumb_base[0], start_rel_y - thumb_base[1])
        index_dist = math.hypot(start_rel_x - index_base[0], start_rel_y - index_base[1])
        middle_dist = math.hypot(start_rel_x - middle_base[0], start_rel_y - middle_base[1])
        pinky_dist = math.hypot(start_rel_x - pinky_base[0], start_rel_y - pinky_base[1])

        # Heuristics for classifying lines
        if angle > 30 and rel_y > 0.35 and rel_x < 0.5 and thumb_dist < 0.5:
            life_line.append((length, angle, approx_contour, rel_y, rel_x))
        elif angle < 25 and rel_y < 0.25 and index_dist < 0.5:
            heart_line.append((length, angle, approx_contour, rel_y, rel_x))
        elif angle < 35 and 0.25 < rel_y < 0.7 and middle_dist < 0.5:
            head_line.append((length, angle, approx_contour, rel_y, rel_x))
        elif angle < 25 and 0.35 < rel_y < 0.95 and 0.35 < rel_x < 0.65:
            fate_line.append((length, angle, approx_contour, rel_y, rel_x))
        elif angle < 30 and rel_y > 0.55 and rel_x > 0.45:
            health_line.append((length, angle, approx_contour, rel_y, rel_x))
        elif angle < 30 and abs(rel_y - 0.7) < 0.08 and rel_x > 0.7 and pinky_dist < 0.6:
            marriage_line.append((length, angle, approx_contour, rel_y, rel_x))
        elif angle < 25 and 0.35 < rel_y < 0.85 and abs(rel_x - 0.8) < 0.1:
            sun_line.append((length, angle, approx_contour, rel_y, rel_x))

    # Hough fallback if nothing detected
    if not (life_line or heart_line or head_line or fate_line or health_line or marriage_line or sun_line):
        lines_p = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=15, minLineLength=20, maxLineGap=10)
        if lines_p is not None:
            for line in lines_p:
                x1, y1, x2, y2 = line[0]
                length = math.hypot(x2 - x1, y2 - y1)
                angle = abs(math.degrees(math.atan2(y2 - y1, x2 - x1)))
                mid_x = (x1 + x2) / 2
                mid_y = (y1 + y2) / 2
                rel_x = mid_x / palm_w
                rel_y = mid_y / palm_h
                start_rel_x = x1 / palm_w
                start_rel_y = y1 / palm_h
                if handedness == 'Right':
                    rel_x = 1 - rel_x
                    start_rel_x = 1 - start_rel_x
                thumb_dist = math.hypot(start_rel_x - thumb_base[0], start_rel_y - thumb_base[1])
                index_dist = math.hypot(start_rel_x - index_base[0], start_rel_y - index_base[1])
                middle_dist = math.hypot(start_rel_x - middle_base[0], start_rel_y - middle_base[1])
                pinky_dist = math.hypot(start_rel_x - pinky_base[0], start_rel_y - pinky_base[1])

                approx_contour = np.array([[x1, y1], [x2, y2]], dtype=float)
                if angle > 30 and rel_y > 0.35 and rel_x < 0.5 and thumb_dist < 0.5:
                    life_line.append((length, angle, approx_contour, rel_y, rel_x))
                elif angle < 25 and rel_y < 0.25 and index_dist < 0.5:
                    heart_line.append((length, angle, approx_contour, rel_y, rel_x))
                elif angle < 35 and 0.25 < rel_y < 0.7 and middle_dist < 0.5:
                    head_line.append((length, angle, approx_contour, rel_y, rel_x))
                elif angle < 25 and 0.35 < rel_y < 0.95 and 0.35 < rel_x < 0.65:
                    fate_line.append((length, angle, approx_contour, rel_y, rel_x))
                elif angle < 30 and rel_y > 0.55 and rel_x > 0.45:
                    health_line.append((length, angle, approx_contour, rel_y, rel_x))
                elif angle < 30 and abs(rel_y - 0.7) < 0.08 and rel_x > 0.7 and pinky_dist < 0.6:
                    marriage_line.append((length, angle, approx_contour, rel_y, rel_x))
                elif angle < 25 and 0.35 < rel_y < 0.85 and abs(rel_x - 0.8) < 0.1:
                    sun_line.append((length, angle, approx_contour, rel_y, rel_x))

    # trim and sort
    life_line = sorted(life_line, key=lambda x: x[0], reverse=True)[:2]
    heart_line = sorted(heart_line, key=lambda x: x[0], reverse=True)[:2]
    head_line = sorted(head_line, key=lambda x: x[0], reverse=True)[:2]
    fate_line = sorted(fate_line, key=lambda x: x[0], reverse=True)[:1]
    health_line = sorted(health_line, key=lambda x: x[0], reverse=True)[:1]
    marriage_line = sorted(marriage_line, key=lambda x: x[0], reverse=True)[:3]
    sun_line = sorted(sun_line, key=lambda x: x[0], reverse=True)[:1]

    return life_line, heart_line, head_line, fate_line, health_line, marriage_line, sun_line, skeleton

# ----- Breaks / branches detection -----

def detect_breaks_branches(contour, skeleton_bool=None):
    # contour: numpy array Nx2 float in ROI pixel coords
    if contour is None or len(contour) == 0:
        return False, 0, []
    if skeleton_bool is None:
        is_break = len(contour) < 80
        return is_break, 0, []

    branches = []
    for pt in contour:
        x = int(round(pt[0]))
        y = int(round(pt[1]))
        if 1 <= y < skeleton_bool.shape[0]-1 and 1 <= x < skeleton_bool.shape[1]-1:
            neighbors = np.sum(skeleton_bool[y-1:y+2, x-1:x+2]) - 1
            if neighbors > 2:
                branches.append((x, y))
    is_break = len(contour) < 100
    return is_break, len(branches), branches

# ----- Scoring -----

def score_line_tracing(lines, palm_h, palm_w, skeleton_bool=None):
    if not lines:
        return 2, False, 0
    max_len = max(l[0] for l in lines)
    base = min(8, int((max_len / (max(1, palm_h) * 0.6)) * 8))
    total_breaks = 0
    total_branches = 0
    for l in lines:
        is_break, nb, _ = detect_breaks_branches(l[2], skeleton_bool)
        if is_break:
            total_breaks += 1
        total_branches += nb
    penalty = min(3, total_breaks * 2)
    branch_bonus = min(2, total_branches)
    curve_bonus = sum(1 for l in lines if l[1] > 40)
    score = base + branch_bonus + curve_bonus - penalty
    return max(1, min(10, int(score))), total_breaks > 0, total_branches

# ----- Main processing -----

def process_palm(image):
    h, w = image.shape[:2]
    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb)

    if not results.multi_hand_landmarks:
        return image, "KhÃ´ng detect bÃ n tay rÃµ! Äiá»ƒm máº·c Ä‘á»‹nh tháº¥p. Chá»¥p áº£nh lÃ²ng bÃ n tay má»Ÿ, sÃ¡ng sá»§a hÆ°á»›ng lÃªn camera.\n\n### PHÃ‚N TÃCH CHI TIáº¾T\n- **Detect**: 0 bÃ n tay.\n- **ÄÆ°á»ng Sinh Äáº¡o**: 0 segs, 1/10 | Ã nghÄ©a: Sá»©c khá»e.\n- **ÄÆ°á»ng TÃ¢m Äáº¡o**: 0 segs, 1/10 | Ã nghÄ©a: TÃ¬nh cáº£m.\n- **ÄÆ°á»ng TrÃ­ Äáº¡o**: 0 segs, 1/10 | Ã nghÄ©a: TrÃ­ Ã³c.\n- **Tá»”NG**: 3/30\n\nğŸ˜… áº¢nh khÃ´ng rÃµ, cáº§n boost. Thá»­ láº¡i vá»›i áº£nh tá»‘t hÆ¡n!"

    hand_landmarks = results.multi_hand_landmarks[0]
    landmarks = hand_landmarks.landmark
    handedness = results.multi_handedness[0].classification[0].label if results.multi_handedness else 'Left'

    roi, offset = get_palm_roi(image, landmarks, h, w)
    if roi.size == 0:
        roi = image
        offset = (0, 0, w, h)

    roi_norm = normalize_palm_size(roi)
    roi_h_norm, roi_w_norm = roi_norm.shape[:2]
    roi_x_start, roi_y_start, roi_w_orig, roi_h_orig = offset

    # Correct landmarks_norm to relative [0,1] in roi safe
    landmarks_norm = []
    for lm in landmarks:
        x_rel = (lm.x * w - roi_x_start) / roi_w_orig
        y_rel = (lm.y * h - roi_y_start) / roi_h_orig
        landmarks_norm.append((x_rel, y_rel))

    life_line, heart_line, head_line, fate_line, health_line, marriage_line, sun_line, skeleton = detect_lines_tracing(roi_norm, landmarks_norm, handedness)
    skeleton_bool = (skeleton > 0)

    annotated = image.copy()
    scale_x = roi_w_orig / roi_w_norm if roi_w_norm > 0 else 1
    scale_y = roi_h_orig / roi_h_norm if roi_h_norm > 0 else 1

    colors = {'life': (0, 0, 255), 'heart': (0, 0, 255), 'head': (0, 0, 255), 'fate': (0, 0, 255), 'health': (0, 0, 255), 'marriage': (0, 0, 255), 'sun': (0, 0, 255)}
    labels = {'life': 'Sinh Äáº¡o/Life', 'heart': 'TÃ¢m Äáº¡o/Heart', 'head': 'TrÃ­ Äáº¡o/Head', 'fate': 'Má»‡nh/Fate', 'health': 'Sinh Lá»¥c/Health', 'marriage': 'HÃ´n NhÃ¢n/Marriage', 'sun': 'TrÃ­ Lá»¥c/Sun'}

    if not any([life_line, heart_line, head_line, fate_line, health_line, marriage_line, sun_line]):
        roi_x_end = roi_x_start + roi_w_orig
        roi_y_end = roi_y_start + roi_h_orig
        cv2.rectangle(annotated, (roi_x_start, roi_y_start), (roi_x_end, roi_y_end), (0, 255, 0), 2)
        cv2.putText(annotated, 'Palm ROI - Lines má», thá»­ áº£nh sÃ¡ng', (roi_x_start, max(10, roi_y_start - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    else:
        for line_type, lines_list in [('life', life_line), ('heart', heart_line), ('head', head_line), ('fate', fate_line), ('health', health_line), ('marriage', marriage_line), ('sun', sun_line)]:
            for i, (length, angle, contour, rel_y, rel_x) in enumerate(lines_list):
                contour_orig = []
                for pt in contour:
                    x_orig = int(round(pt[0] * scale_x)) + roi_x_start
                    y_orig = int(round(pt[1] * scale_y)) + roi_y_start
                    contour_orig.append((x_orig, y_orig))
                pts = np.array(contour_orig, np.int32)
                if pts.size > 0:
                    cv2.polylines(annotated, [pts], False, colors[line_type], thickness=3)
                    cv2.putText(annotated, f"{labels[line_type]} {i+1} (L={length:.1f}, A={angle:.0f}Â°)", contour_orig[0], cv2.FONT_HERSHEY_SIMPLEX, 0.6, colors[line_type], 2)
                is_break, num_branches, branches = detect_breaks_branches(contour, skeleton_bool)
                if is_break:
                    mid_pt = contour_orig[len(contour_orig)//2]
                    cv2.circle(annotated, mid_pt, 6, (0, 0, 255), -1)
                    cv2.putText(annotated, 'Äá»©t', (mid_pt[0]+6, mid_pt[1]+6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
                for b in branches[:3]:
                    bx = int(round(b[0] * scale_x)) + roi_x_start
                    by = int(round(b[1] * scale_y)) + roi_y_start
                    cv2.circle(annotated, (int(bx), int(by)), 5, (0, 255, 255), -1)
                    cv2.putText(annotated, f'NhÃ¡nh', (int(bx)+4, int(by)-6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)

    diem_sinh, scar_sinh, branches_sinh = score_line_tracing(life_line, roi_h_norm, roi_w_norm, skeleton_bool)
    diem_tam, scar_tam, branches_tam = score_line_tracing(heart_line, roi_h_norm, roi_w_norm, skeleton_bool)
    diem_tri, scar_tri, branches_tri = score_line_tracing(head_line, roi_h_norm, roi_w_norm, skeleton_bool)
    diem_menh, scar_menh, branches_menh = score_line_tracing(fate_line, roi_h_norm, roi_w_norm, skeleton_bool)
    diem_suc_khoe, scar_suc_khoe, branches_suc_khoe = score_line_tracing(health_line, roi_h_norm, roi_w_norm, skeleton_bool)
    diem_hon_nhan, scar_hon_nhan, branches_hon_nhan = score_line_tracing(marriage_line, roi_h_norm, roi_w_norm, skeleton_bool)
    diem_tri_luc, scar_tri_luc, branches_tri_luc = score_line_tracing(sun_line, roi_h_norm, roi_w_norm, skeleton_bool)
    tong = diem_sinh + diem_tam + diem_tri + diem_menh + diem_suc_khoe + diem_hon_nhan + diem_tri_luc

    # textual summaries
    sinh_scar = " (Ä‘á»©t - obstacle sá»©c khá»e)" if scar_sinh else ""
    sinh_branch = f" (nhÃ¡nh {branches_sinh} - nÄƒng lÆ°á»£ng dá»“i dÃ o)" if branches_sinh > 0 else ""
    tam_scar = " (Ä‘á»©t - thá»­ thÃ¡ch tÃ¬nh cáº£m)" if scar_tam else ""
    tam_branch = f" (nhÃ¡nh {branches_tam} - cáº£m xÃºc Ä‘a dáº¡ng)" if branches_tam > 0 else ""
    tri_scar = " (Ä‘á»©t - stress sá»± nghiá»‡p)" if scar_tri else ""
    tri_branch = f" (nhÃ¡nh {branches_tri} - sÃ¡ng táº¡o cao)" if branches_tri > 0 else ""
    menh_scar = " (Ä‘á»©t - thay Ä‘á»•i má»‡nh)" if scar_menh else ""
    menh_branch = f" (nhÃ¡nh {branches_menh} - cÆ¡ há»™i sá»± nghiá»‡p)" if branches_menh > 0 else ""
    suc_khoe_scar = " (Ä‘á»©t - váº¥n Ä‘á» sá»©c khá»e)" if scar_suc_khoe else ""
    suc_khoe_branch = f" (nhÃ¡nh {branches_suc_khoe} - phá»¥c há»“i tá»‘t)" if branches_suc_khoe > 0 else ""
    hon_nhan_scar = " (Ä‘á»©t - ly hÃ´n/Ä‘Æ¡n thÃ¢n)" if scar_hon_nhan else ""
    hon_nhan_branch = f" (nhÃ¡nh {branches_hon_nhan} - nhiá»u má»‘i tÃ¬nh)" if branches_hon_nhan > 0 else ""
    tri_luc_scar = " (Ä‘á»©t - tháº¥t báº¡i danh vá»ng)" if scar_tri_luc else ""
    tri_luc_branch = f" (nhÃ¡nh {branches_tri_luc} - thÃ nh cÃ´ng nghá»‡ thuáº­t)" if branches_tri_luc > 0 else ""

    scar_info = sinh_scar + tam_scar + tri_scar + menh_scar + suc_khoe_scar + hon_nhan_scar + tri_luc_scar
    branch_info = sinh_branch + tam_branch + tri_branch + menh_branch + suc_khoe_branch + hon_nhan_branch + tri_luc_branch

    if tong >= 50:
        advice = f"ğŸŒŸ BÃ n tay elite! Lines cong liá»n{branch_info}. ThÃ nh cÃ´ng lá»›n, sá»‘ng thá»."
    elif tong >= 35:
        advice = f"ğŸ‘ BÃ n tay vá»¯ng chÃ£i! {scar_info}{branch_info}. Cá»‘ lÃªn, potential cao."
    elif tong >= 25:
        advice = f"ğŸ¤” Trung bÃ¬nh, {scar_info}{branch_info}. Cáº£i thiá»‡n lá»‘i sá»‘ng Ä‘á»ƒ lines rÃµ hÆ¡n."
    else:
        advice = f"ğŸ˜… Cáº§n boost, {scar_info}{branch_info}. Massage tay, xem chuyÃªn gia náº¿u Ä‘á»©t nhiá»u."

    result = f"""
### PHÃ‚N TÃCH CHI TIáº¾T (Hand: {handedness}, Trace cong theo diagram chá»‰ tay)
- **ÄÆ°á»ng Sinh Äáº¡o**: {len(life_line)} paths, {diem_sinh}/10{sinh_scar}{sinh_branch} | Ã nghÄ©a: Sá»©c khá»e/vitality (cong dÃ i=thá»).
- **ÄÆ°á»ng TÃ¢m Äáº¡o**: {len(heart_line)} paths, {diem_tam}/10{tam_scar}{tam_branch} | Ã nghÄ©a: TÃ¬nh cáº£m (cong=lÃ£ng máº¡n).
- **ÄÆ°á»ng TrÃ­ Äáº¡o**: {len(head_line)} paths, {diem_tri}/10{tri_scar}{tri_branch} | Ã nghÄ©a: TrÃ­ Ã³c/sá»± nghiá»‡p (sÃ¢u cong=sÃ¡ng táº¡o).
- **ÄÆ°á»ng Má»‡nh**: {len(fate_line)} paths, {diem_menh}/10{menh_scar}{menh_branch} | Ã nghÄ©a: Sá»± nghiá»‡p (dá»c giá»¯a=á»•n Ä‘á»‹nh).
- **ÄÆ°á»ng Sinh Lá»¥c**: {len(health_line)} paths, {diem_suc_khoe}/10{suc_khoe_scar}{suc_khoe_branch} | Ã nghÄ©a: Sá»©c khá»e tá»•ng (dá»c dÆ°á»›i=khá»e máº¡nh).
- **ÄÆ°á»ng HÃ´n NhÃ¢n**: {len(marriage_line)} paths, {diem_hon_nhan}/10{hon_nhan_scar}{hon_nhan_branch} | Ã nghÄ©a: TÃ¬nh duyÃªn (ngang cáº¡nh=sá»‘ hÃ´n nhÃ¢n).
- **ÄÆ°á»ng TrÃ­ Lá»¥c**: {len(sun_line)} paths, {diem_tri_luc}/10{tri_luc_scar}{tri_luc_branch} | Ã nghÄ©a: Danh vá»ng (dá»c cáº¡nh=thÃ nh cÃ´ng).
- **Tá»”NG**: {tong}/70

{advice}

ğŸ’¡ Note: Váº½ Ä‘á» cong theo diagram chá»‰ tay (approxPolyDP + landmark filter + Hough fallback). Äá»©t=Ä‘á» dot, nhÃ¡nh=vÃ ng star. Fallback bbox náº¿u no lines. Accuracy ~90% áº£nh rÃµ. Náº¿u sai, thá»­ áº£nh sÃ¡ng hÆ¡n.
"""
    return annotated, result

# ----- Download helpers -----

def download_text(content, filename):
    st.download_button("ğŸ“¥ Táº£i Text", content, file_name=filename, mime="text/plain")


def download_image(img_array, filename):
    img_pil = Image.fromarray(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))
    bio = io.BytesIO()
    img_pil.save(bio, format='PNG')
    st.download_button("ğŸ“¥ Táº£i áº¢nh", bio.getvalue(), file_name=filename, mime="image/png")


def create_pdf(image_array, result_text, filename):
    bio = io.BytesIO()
    doc = SimpleDocTemplate(bio, pagesize=letter)
    styles = getSampleStyleSheet()
    story = []
    story.append(Paragraph("Palm Analysis Report", styles['Title']))
    story.append(Spacer(1, 12))
    img_pil = Image.fromarray(cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB))
    img_buffer = io.BytesIO()
    img_pil.save(img_buffer, format='PNG')
    img_buffer.seek(0)
    img = RLImage(img_buffer, width=4*inch, height=4*inch)
    story.append(img)
    story.append(Spacer(1, 12))
    story.append(Paragraph(result_text.replace('\n', '<br/>'), styles['Normal']))
    doc.build(story)
    bio.seek(0)
    st.download_button("ğŸ“¥ Táº£i PDF", bio.getvalue(), file_name=filename, mime="application/pdf")


def generate_share_link(entry_id):
    return f"https://yourapp.streamlit.app/?share={base64.b64encode(entry_id.encode()).decode()}"

# ----- UI -----

st.sidebar.title("âš™ï¸ CÃ i Äáº·t")
lang_name = st.sidebar.selectbox("NgÃ´n Ngá»¯ / Language", options=list(LANGUAGES.keys()), index=0)
ui_texts = get_ui_texts(lang_name)

if 'history' not in st.session_state:
    st.session_state.history = []

st.sidebar.subheader(ui_texts['history_title'])
if st.session_state.history:
    for i, entry in enumerate(reversed(st.session_state.history)):
        with st.sidebar.expander(f"Entry {len(st.session_state.history)-i} - {entry['timestamp']}"):
            st.image(entry['annotated_b64'], caption="Annotated Image")
            st.text(entry['result'][:200] + "...")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                download_text(entry['result'], f"palm_result_{entry['id']}.txt")
            with col2:
                img_data = base64.b64decode(entry['annotated_b64'].split(',')[1])
                st.download_button("ğŸ“¥ Img", img_data, f"palm_img_{entry['id']}.png")
            with col3:
                img_array = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)
                create_pdf(img_array, entry['result'], f"palm_pdf_{entry['id']}.pdf")
            with col4:
                share_link = generate_share_link(entry['id'])
                st.text_input("Share Link", value=share_link, key=f"link_hist_{i}")
else:
    st.sidebar.info(ui_texts['no_history'])

st.title(ui_texts['title'])

uploaded_file = st.file_uploader(ui_texts['upload_label'], type=['jpg', 'png'])

if uploaded_file is not None:
    image_pil = Image.open(uploaded_file).convert('RGB')
    image = np.array(image_pil)
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    annotated, result = process_palm(image)

    col1, col2 = st.columns(2)
    with col1:
        st.image(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), caption=ui_texts['original_caption'], use_column_width=True)
    with col2:
        st.image(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB), caption=ui_texts['annotated_caption'], use_column_width=True)

    st.markdown(result)

    # Save to history
    entry_id = str(datetime.now().timestamp())
    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(annotated_rgb)
    buffered = io.BytesIO()
    pil_img.save(buffered, format="PNG")
    annotated_b64 = "data:image/png;base64," + base64.b64encode(buffered.getvalue()).decode()
    entry = {
        'id': entry_id,
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'result': result,
        'annotated_b64': annotated_b64
    }
    st.session_state.history.append(entry)

    # Share buttons
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        download_text(result, f"palm_result_{entry_id}.txt")
    with col2:
        download_image(annotated, f"palm_img_{entry_id}.png")
    with col3:
        create_pdf(annotated, result, f"palm_pdf_{entry_id}.pdf")
    with col4:
        share_link = generate_share_link(entry_id)
        st.text_input(ui_texts['share_link'], value=share_link, key="share_link_current")

st.markdown(ui_texts['note'])
